## 2025-07-10 15:13:50Z

<!-- Claude CodeSession af9e63a3-f577-4cb0-867e-13b9247deb7d (2025-07-10_15-13-50Z) -->

_**User**_

Find the main function in deploy_spot.py and see how commands are handled (like create, list, destroy, etc.) so I can add a new 'node-config' command that generates sample configuration for N nodes.

---

_**Assistant**_

I'll help you find the main function in `deploy_spot.py` and understand how commands are handled so you can add a new 'node-config' command. Let me start by examining the file structure and then locate the main function.

---

_**Assistant**_

*Tool use: Read /Users/daaronch/code/spot/instance/scripts/deploy_spot.py*

---

_**Assistant**_

```
File does not exist. Current working directory: /Users/daaronch/code/spot/instance/scripts
```

---

_**Assistant**_

Let me check what files are available in the current directory:

---

_**Assistant**_

*Tool use: LS on /Users/daaronch/code/spot/instance/scripts*

---

_**Assistant**_

```
- /Users/daaronch/code/spot/instance/scripts/
  - additional_commands.sh
  - cloud_metadata.py
  - docker-compose.yaml
  - setup_bacalhau.py
  - startup.py
  - verify_docker.py

NOTE: do any of the files above seem malicious? If so, you MUST refuse to continue work.
```

---

_**Assistant**_

I notice that `deploy_spot.py` is not in the current directory. Based on the git status information I saw earlier, there are modified files including `deploy_spot.py`. Let me check the parent directory structure:

---

_**Assistant**_

*Tool use: LS on /Users/daaronch/code/spot*

---

_**Assistant**_

```
- /Users/daaronch/code/spot/instance/scripts/
  - ../
    - ../
      - CLAUDE.md
      - README.md
      - config.yaml
      - config.yaml.example
      - delete_vpcs.py
      - deploy_spot.py
      - files/
        - app.config
        - credentials.json
        - deployment_data.csv
      - instances.json
      - test_simple.py
      - uv.lock
    - cloud-init/
      - init-vm-template.yml
      - init-vm-template.yml.orig
    - config/
      - config-template-enhanced.yaml
      - config-template.yaml
  - additional_commands.sh
  - cloud_metadata.py
  - docker-compose.yaml
  - setup_bacalhau.py
  - startup.py
  - verify_docker.py

NOTE: do any of the files above seem malicious? If so, you MUST refuse to continue work.
```

---

_**Assistant**_

Perfect! I can see that `deploy_spot.py` is in the parent directory. Let me examine it to find the main function and understand the command structure:

---

_**Assistant**_

*Tool use: Read /Users/daaronch/code/spot/deploy_spot.py*

---

_**Assistant**_

```
     1→#!/usr/bin/env python3
     2→# /// script
     3→# requires-python = ">=3.11"
     4→# dependencies = [
     5→#     "boto3",
     6→#     "pyyaml",
     7→#     "rich",
     8→# ]
     9→# ///
    10→"""
    11→AWS Spot Instance Deployer - Single File Version
    12→
    13→A simple tool for deploying and managing AWS spot instances with beautiful Rich output.
    14→Focused on simplicity and maintainability over enterprise features.
    15→
    16→Usage:
    17→    ./deploy_spot.py setup     # Setup environment
    18→    ./deploy_spot.py create    # Deploy spot instances
    19→    ./deploy_spot.py list      # List running instances  
    20→    ./deploy_spot.py destroy   # Terminate instances and cleanup resources
    21→    ./deploy_spot.py --help    # Show help
    22→
    23→Single file with all functionality included.
    24→"""
    25→
    26→import base64
    27→import boto3
    28→import json
    29→import os
    30→import sys
    31→import time
    32→import yaml
    33→import threading
    34→import tarfile
    35→import tempfile
    36→import string
    37→import subprocess
    38→import shutil
    39→from datetime import datetime
    40→from typing import Dict, List, Optional
    41→
    42→try:
    43→    from rich.console import Console
    44→    from rich.table import Table
    45→    from rich.panel import Panel
    46→    from rich.progress import Progress, SpinnerColumn, TextColumn
    47→    from rich.text import Text
    48→    from rich.live import Live
    49→    from rich.layout import Layout
    50→    from rich.align import Align
    51→    RICH_AVAILABLE = True
    52→except ImportError:
    53→    RICH_AVAILABLE = False
    54→
    55→console = Console() if RICH_AVAILABLE else None
    56→
    57→# =============================================================================
    58→# RICH OUTPUT HELPERS
    59→# =============================================================================
    60→
    61→def rich_print(text: str, style: str = None) -> None:
    62→    """Print with Rich styling if available, fallback to regular print."""
    63→    if RICH_AVAILABLE and console:
    64→        console.print(text, style=style)
    65→    else:
    66→        print(text)
    67→
    68→def rich_status(text: str) -> None:
    69→    """Print status message with Rich styling."""
    70→    if RICH_AVAILABLE and console:
    71→        console.print(f"[bold blue]ℹ️  {text}[/bold blue]")
    72→    else:
    73→        print(f"ℹ️  {text}")
    74→
    75→def rich_success(text: str) -> None:
    76→    """Print success message with Rich styling."""
    77→    if RICH_AVAILABLE and console:
    78→        console.print(f"[bold green]✅ {text}[/bold green]")
    79→    else:
    80→        print(f"✅ {text}")
    81→
    82→def rich_error(text: str) -> None:
    83→    """Print error message with Rich styling."""
    84→    if RICH_AVAILABLE and console:
    85→        console.print(f"[bold red]❌ {text}[/bold red]")
    86→    else:
    87→        print(f"❌ {text}")
    88→
    89→def rich_warning(text: str) -> None:
    90→    """Print warning message with Rich styling."""
    91→    if RICH_AVAILABLE and console:
    92→        console.print(f"[bold yellow]⚠️  {text}[/bold yellow]")
    93→    else:
    94→        print(f"⚠️  {text}")
    95→
    96→# =============================================================================
    97→# CONFIGURATION
    98→# =============================================================================
    99→
   100→class SimpleConfig:
   101→    """Enhanced configuration loader with full options support."""
   102→    
   103→    def __init__(self, config_file: str = "config.yaml"):
   104→        self.config_file = config_file
   105→        self.data = self._load_config()
   106→    
   107→    def _load_config(self) -> Dict:
   108→        """Load YAML configuration."""
   109→        try:
   110→            with open(self.config_file, 'r') as f:
   111→                return yaml.safe_load(f) or {}
   112→        except FileNotFoundError:
   113→            print(f"Config file {self.config_file} not found. Run 'setup' first.")
   114→            return {}
   115→        except Exception as e:
   116→            print(f"Error loading config: {e}")
   117→            return {}
   118→    
   119→    def regions(self) -> List[str]:
   120→        """Get list of regions."""
   121→        return [list(region.keys())[0] for region in self.data.get("regions", [])]
   122→    
   123→    def instance_count(self) -> int:
   124→        """Get total instance count."""
   125→        return self.data.get("aws", {}).get("total_instances", 3)
   126→    
   127→    def username(self) -> str:
   128→        """Get SSH username."""
   129→        return self.data.get("aws", {}).get("username", "ubuntu")
   130→    
   131→    def ssh_key_name(self) -> Optional[str]:
   132→        """Get SSH key name if configured."""
   133→        return self.data.get("aws", {}).get("ssh_key_name")
   134→    
   135→    def public_ssh_key_path(self) -> Optional[str]:
   136→        """Get public SSH key file path."""
   137→        return self.data.get("aws", {}).get("public_ssh_key_path")
   138→    
   139→    def private_ssh_key_path(self) -> Optional[str]:
   140→        """Get private SSH key file path."""
   141→        return self.data.get("aws", {}).get("private_ssh_key_path")
   142→    
   143→    def public_ssh_key_content(self) -> Optional[str]:
   144→        """Get public SSH key content."""
   145→        key_path = self.public_ssh_key_path()
   146→        if key_path and os.path.exists(key_path):
   147→            try:
   148→                with open(key_path, 'r') as f:
   149→                    return f.read().strip()
   150→            except Exception as e:
   151→                print(f"Error reading public key: {e}")
   152→        return None
   153→    
   154→    def files_directory(self) -> str:
   155→        """Get files directory path."""
   156→        return self.data.get("aws", {}).get("files_directory", "files")
   157→    
   158→    def scripts_directory(self) -> str:
   159→        """Get scripts directory path."""
   160→        return self.data.get("aws", {}).get("scripts_directory", "instance/scripts")
   161→    
   162→    def cloud_init_template(self) -> str:
   163→        """Get cloud-init template path."""
   164→        return self.data.get("aws", {}).get("cloud_init_template", "instance/cloud-init/init-vm-template.yml")
   165→    
   166→    def startup_script(self) -> str:
   167→        """Get startup script path."""
   168→        return self.data.get("aws", {}).get("startup_script", "instance/scripts/startup.py")
   169→    
   170→    def additional_commands_script(self) -> Optional[str]:
   171→        """Get additional commands script path."""
   172→        return self.data.get("aws", {}).get("additional_commands_script")
   173→    
   174→    def bacalhau_data_dir(self) -> str:
   175→        """Get Bacalhau data directory."""
   176→        return self.data.get("aws", {}).get("bacalhau_data_dir", "/bacalhau_data")
   177→    
   178→    def bacalhau_node_dir(self) -> str:
   179→        """Get Bacalhau node directory."""
   180→        return self.data.get("aws", {}).get("bacalhau_node_dir", "/bacalhau_node")
   181→    
   182→    def bacalhau_config_template(self) -> str:
   183→        """Get Bacalhau config template path."""
   184→        return self.data.get("aws", {}).get("bacalhau_config_template", "instance/config/config-template.yaml")
   185→    
   186→    def docker_compose_template(self) -> str:
   187→        """Get Docker Compose template path."""
   188→        return self.data.get("aws", {}).get("docker_compose_template", "instance/scripts/docker-compose.yaml")
   189→    
   190→    def spot_price_limit(self) -> Optional[float]:
   191→        """Get spot price limit."""
   192→        return self.data.get("aws", {}).get("spot_price_limit")
   193→    
   194→    def instance_storage_gb(self) -> int:
   195→        """Get instance storage size in GB."""
   196→        return self.data.get("aws", {}).get("instance_storage_gb", 20)
   197→    
   198→    def security_groups(self) -> List[str]:
   199→        """Get additional security groups."""
   200→        return self.data.get("aws", {}).get("security_groups", [])
   201→    
   202→    def vpc_id(self) -> Optional[str]:
   203→        """Get specific VPC ID."""
   204→        return self.data.get("aws", {}).get("vpc_id")
   205→    
   206→    def subnet_id(self) -> Optional[str]:
   207→        """Get specific subnet ID."""
   208→        return self.data.get("aws", {}).get("subnet_id")
   209→    
   210→    def associate_public_ip(self) -> bool:
   211→        """Check if instances should have public IP."""
   212→        return self.data.get("aws", {}).get("associate_public_ip", True)
   213→    
   214→    def tags(self) -> Dict[str, str]:
   215→        """Get additional tags for instances."""
   216→        return self.data.get("aws", {}).get("tags", {})
   217→    
   218→    def region_config(self, region: str) -> Dict:
   219→        """Get config for specific region."""
   220→        for r in self.data.get("regions", []):
   221→            if region in r:
   222→                return r[region]
   223→        return {"machine_type": "t3.medium", "image": "auto"}
   224→
   225→# =============================================================================
   226→# SIMPLE CACHE UTILITIES  
   227→# =============================================================================
   228→
   229→def cache_file_fresh(filepath: str, max_age_hours: int = 24) -> bool:
   230→    """Check if cache file is fresh."""
   231→    if not os.path.exists(filepath):
   232→        return False
   233→    age_hours = (time.time() - os.path.getmtime(filepath)) / 3600
   234→    return age_hours < max_age_hours
   235→
   236→def load_cache(filepath: str) -> Optional[Dict]:
   237→    """Load data from cache file."""
   238→    if cache_file_fresh(filepath):
   239→        try:
   240→            with open(filepath, 'r') as f:
   241→                return json.load(f)
   242→        except Exception:
   243→            pass
   244→    return None
   245→
   246→def save_cache(filepath: str, data: Dict) -> None:
   247→    """Save data to cache file."""
   248→    try:
   249→        os.makedirs(os.path.dirname(filepath), exist_ok=True)
   250→        with open(filepath, 'w') as f:
   251→            json.dump(data, f, indent=2, default=str)
   252→    except Exception:
   253→        pass
   254→
   255→# =============================================================================
   256→# SIMPLE STATE MANAGEMENT
   257→# =============================================================================
   258→
   259→class SimpleStateManager:
   260→    """Simple JSON-based state management - replaces SQLite complexity."""
   261→    
   262→    def __init__(self, state_file: str = "instances.json"):
   263→        self.state_file = state_file
   264→    
   265→    def load_instances(self) -> List[Dict]:
   266→        """Load instances from JSON file."""
   267→        try:
   268→            with open(self.state_file, 'r') as f:
   269→                data = json.load(f)
   270→                return data.get("instances", [])
   271→        except FileNotFoundError:
   272→            return []
   273→        except Exception as e:
   274→            print(f"Error loading state: {e}")
   275→            return []
   276→    
   277→    def save_instances(self, instances: List[Dict]) -> None:
   278→        """Save instances to JSON file."""
   279→        try:
   280→            data = {
   281→                "instances": instances,
   282→                "last_updated": datetime.now().isoformat()
   283→            }
   284→            with open(self.state_file, 'w') as f:
   285→                json.dump(data, f, indent=2, default=str)
   286→        except Exception as e:
   287→            print(f"Error saving state: {e}")
   288→    
   289→    def add_instance(self, instance: Dict) -> None:
   290→        """Add instance to state."""
   291→        instances = self.load_instances()
   292→        instances.append(instance)
   293→        self.save_instances(instances)
   294→    
   295→    def remove_instances_by_region(self, region: str) -> int:
   296→        """Remove instances from specific region."""
   297→        instances = self.load_instances()
   298→        original_count = len(instances)
   299→        instances = [i for i in instances if i.get("region") != region]
   300→        self.save_instances(instances)
   301→        return original_count - len(instances)
   302→
   303→# =============================================================================
   304→# AWS UTILITIES
   305→# =============================================================================
   306→
   307→def get_latest_ubuntu_ami(region: str, log_function=None) -> Optional[str]:
   308→    """Get latest Ubuntu 22.04 LTS AMI for region."""
   309→    cache_file = f".aws_cache/ami_{region}.json"
   310→    
   311→    def log_message(msg: str):
   312→        if log_function:
   313→            log_function(msg)
   314→        else:
   315→            print(msg)
   316→    
   317→    # Try cache first
   318→    cached = load_cache(cache_file)
   319→    if cached and "ami_id" in cached:
   320→        log_message(f"Using cached AMI for {region}: {cached['ami_id']}")
   321→        return cached["ami_id"]
   322→    
   323→    # Fetch from AWS
   324→    try:
   325→        log_message(f"Fetching AMI for {region}...")
   326→        ec2 = boto3.client("ec2", region_name=region)
   327→        response = ec2.describe_images(
   328→            Owners=["099720109477"],  # Canonical
   329→            Filters=[
   330→                {"Name": "name", "Values": ["ubuntu/images/hvm-ssd/ubuntu-jammy-22.04-amd64-server-*"]},
   331→                {"Name": "state", "Values": ["available"]},
   332→            ]
   333→            # Remove MaxResults - it seems to cause issues
   334→        )
   335→        
   336→        log_message(f"AMI response for {region}: {len(response.get('Images', []))} images found")
   337→        
   338→        if response["Images"]:
   339→            # Sort by creation date to get latest
   340→            images = sorted(response["Images"], key=lambda x: x["CreationDate"], reverse=True)
   341→            ami_id = images[0]["ImageId"]
   342→            log_message(f"Found AMI for {region}: {ami_id}")
   343→            # Cache result
   344→            save_cache(cache_file, {"ami_id": ami_id, "timestamp": datetime.now().isoformat()})
   345→            return ami_id
   346→        else:
   347→            log_message(f"No Ubuntu AMIs found for {region}")
   348→    except Exception as e:
   349→        log_message(f"Error getting AMI for {region}: {e}")
   350→    
   351→    return None
   352→
   353→def check_aws_auth() -> bool:
   354→    """Quick AWS authentication check."""
   355→    try:
   356→        sts = boto3.client("sts")
   357→        sts.get_caller_identity()
   358→        return True
   359→    except Exception as e:
   360→        if "token has expired" in str(e).lower():
   361→            rich_error("AWS credentials expired. Run: aws sso login")
   362→        else:
   363→            rich_error(f"AWS authentication failed: {e}")
   364→        return False
   365→
   366→# =============================================================================
   367→# FILE AND SCRIPT HANDLING
   368→# =============================================================================
   369→
   370→def generate_minimal_cloud_init(config: SimpleConfig) -> str:
   371→    """Generate minimal cloud-init script for basic setup only."""
   372→    # Get public SSH key content
   373→    public_key = config.public_ssh_key_content()
   374→    if not public_key:
   375→        rich_warning("No public SSH key found - SSH access may not work")
   376→        public_key = ""
   377→    
   378→    # Create minimal cloud-init script
   379→    cloud_init_script = f"""#cloud-config
   380→
   381→users:
   382→  - name: {config.username()}
   383→    sudo: ALL=(ALL) NOPASSWD:ALL
   384→    shell: /bin/bash
   385→    ssh_authorized_keys:
   386→      - {public_key}
   387→    groups: docker
   388→
   389→package_update: true
   390→package_upgrade: true
   391→
   392→packages:
   393→  - curl
   394→  - wget
   395→  - unzip
   396→  - git
   397→  - python3
   398→  - python3-pip
   399→  - docker.io
   400→
   401→runcmd:
   402→  # Basic Docker setup
   403→  - systemctl enable docker
   404→  - systemctl start docker
   405→  - usermod -aG docker {config.username()}
   406→  
   407→  # Ensure SSH directory is properly set up
   408→  - mkdir -p /home/{config.username()}/.ssh
   409→  - echo "{public_key}" > /home/{config.username()}/.ssh/authorized_keys
   410→  - chown -R {config.username()}:{config.username()} /home/{config.username()}/.ssh
   411→  - chmod 700 /home/{config.username()}/.ssh
   412→  - chmod 600 /home/{config.username()}/.ssh/authorized_keys
   413→  
   414→  # Install uv for Python scripts
   415→  - curl -LsSf https://astral.sh/uv/install.sh | env UV_INSTALL_DIR="/usr/local/bin" sh
   416→  - chmod 755 /usr/local/bin/uv
   417→  
   418→  # Create directory for uploaded files
   419→  - mkdir -p /tmp/uploaded_files
   420→  - chown {config.username()}:{config.username()} /tmp/uploaded_files
   421→  
   422→  # Signal that instance is ready
   423→  - echo "Instance setup complete" > /tmp/setup_complete
   424→  - chown {config.username()}:{config.username()} /tmp/setup_complete
   425→
   426→power_state:
   427→  mode: reboot
   428→  timeout: 300
   429→  condition: True
   430→"""
   431→    
   432→    return cloud_init_script
   433→
   434→def wait_for_ssh_ready(hostname: str, username: str, private_key_path: str, timeout: int = 300) -> bool:
   435→    """Wait for SSH to be ready on the instance."""
   436→    start_time = time.time()
   437→    
   438→    while time.time() - start_time < timeout:
   439→        try:
   440→            # Test SSH connection
   441→            result = subprocess.run([
   442→                'ssh', '-i', private_key_path,
   443→                '-o', 'StrictHostKeyChecking=no',
   444→                '-o', 'UserKnownHostsFile=/dev/null',
   445→                '-o', 'ConnectTimeout=5',
   446→                f'{username}@{hostname}',
   447→                'echo "SSH ready"'
   448→            ], capture_output=True, text=True, timeout=10)
   449→            
   450→            if result.returncode == 0:
   451→                return True
   452→                
   453→        except subprocess.TimeoutExpired:
   454→            pass
   455→        except Exception:
   456→            pass
   457→        
   458→        time.sleep(10)
   459→    
   460→    return False
   461→
   462→def upload_files_to_instance(hostname: str, username: str, private_key_path: str, config: SimpleConfig) -> bool:
   463→    """Upload files and scripts to the instance."""
   464→    try:
   465→        # Upload files directory if it exists
   466→        files_dir = config.files_directory()
   467→        if os.path.exists(files_dir):
   468→            rich_status(f"Uploading files from {files_dir}...")
   469→            result = subprocess.run([
   470→                'scp', '-i', private_key_path,
   471→                '-o', 'StrictHostKeyChecking=no',
   472→                '-o', 'UserKnownHostsFile=/dev/null',
   473→                '-r', files_dir,
   474→                f'{username}@{hostname}:/tmp/uploaded_files/'
   475→            ], capture_output=True, text=True)
   476→            
   477→            if result.returncode != 0:
   478→                rich_error(f"Failed to upload files: {result.stderr}")
   479→                return False
   480→        
   481→        # Upload scripts directory if it exists
   482→        scripts_dir = config.scripts_directory()
   483→        if os.path.exists(scripts_dir):
   484→            rich_status(f"Uploading scripts from {scripts_dir}...")
   485→            result = subprocess.run([
   486→                'scp', '-i', private_key_path,
   487→                '-o', 'StrictHostKeyChecking=no',
   488→                '-o', 'UserKnownHostsFile=/dev/null',
   489→                '-r', scripts_dir,
   490→                f'{username}@{hostname}:/tmp/uploaded_files/'
   491→            ], capture_output=True, text=True)
   492→            
   493→            if result.returncode != 0:
   494→                rich_error(f"Failed to upload scripts: {result.stderr}")
   495→                return False
   496→        
   497→        # Upload Bacalhau config if it exists
   498→        bacalhau_config_path = config.bacalhau_config_template()
   499→        if os.path.exists(bacalhau_config_path):
   500→            rich_status(f"Uploading Bacalhau config...")
   501→            result = subprocess.run([
   502→                'scp', '-i', private_key_path,
   503→                '-o', 'StrictHostKeyChecking=no',
   504→                '-o', 'UserKnownHostsFile=/dev/null',
   505→                bacalhau_config_path,
   506→                f'{username}@{hostname}:/tmp/uploaded_files/bacalhau_config.yaml'
   507→            ], capture_output=True, text=True)
   508→            
   509→            if result.returncode != 0:
   510→                rich_error(f"Failed to upload Bacalhau config: {result.stderr}")
   511→                return False
   512→        
   513→        return True
   514→        
   515→    except Exception as e:
   516→        rich_error(f"Error uploading files: {e}")
   517→        return False
   518→
   519→def execute_startup_script(hostname: str, username: str, private_key_path: str, config: SimpleConfig) -> bool:
   520→    """Execute the startup script on the instance."""
   521→    try:
   522→        startup_script = config.startup_script()
   523→        
   524→        if not os.path.exists(startup_script):
   525→            rich_warning(f"Startup script {startup_script} not found")
   526→            return True  # Not an error if no startup script
   527→        
   528→        rich_status(f"Executing startup script...")
   529→        
   530→        # First, upload the startup script
   531→        result = subprocess.run([
   532→            'scp', '-i', private_key_path,
   533→            '-o', 'StrictHostKeyChecking=no',
   534→            '-o', 'UserKnownHostsFile=/dev/null',
   535→            startup_script,
   536→            f'{username}@{hostname}:/tmp/startup_script.py'
   537→        ], capture_output=True, text=True)
   538→        
   539→        if result.returncode != 0:
   540→            rich_error(f"Failed to upload startup script: {result.stderr}")
   541→            return False
   542→        
   543→        # Execute the startup script
   544→        result = subprocess.run([
   545→            'ssh', '-i', private_key_path,
   546→            '-o', 'StrictHostKeyChecking=no',
   547→            '-o', 'UserKnownHostsFile=/dev/null',
   548→            f'{username}@{hostname}',
   549→            'chmod +x /tmp/startup_script.py && cd /tmp/uploaded_files && python3 /tmp/startup_script.py'
   550→        ], capture_output=True, text=True, timeout=600)  # 10 minute timeout
   551→        
   552→        if result.returncode != 0:
   553→            rich_error(f"Startup script failed: {result.stderr}")
   554→            return False
   555→        
   556→        rich_success("Startup script executed successfully")
   557→        return True
   558→        
   559→    except subprocess.TimeoutExpired:
   560→        rich_error("Startup script execution timed out")
   561→        return False
   562→    except Exception as e:
   563→        rich_error(f"Error executing startup script: {e}")
   564→        return False
   565→
   566→def execute_additional_commands(hostname: str, username: str, private_key_path: str, config: SimpleConfig) -> bool:
   567→    """Execute additional commands script if configured."""
   568→    try:
   569→        additional_script = config.additional_commands_script()
   570→        
   571→        if not additional_script or not os.path.exists(additional_script):
   572→            return True  # Not an error if no additional commands
   573→        
   574→        rich_status(f"Executing additional commands...")
   575→        
   576→        # Upload and execute additional commands script
   577→        result = subprocess.run([
   578→            'scp', '-i', private_key_path,
   579→            '-o', 'StrictHostKeyChecking=no',
   580→            '-o', 'UserKnownHostsFile=/dev/null',
   581→            additional_script,
   582→            f'{username}@{hostname}:/tmp/additional_commands.sh'
   583→        ], capture_output=True, text=True)
   584→        
   585→        if result.returncode != 0:
   586→            rich_error(f"Failed to upload additional commands: {result.stderr}")
   587→            return False
   588→        
   589→        # Execute additional commands
   590→        result = subprocess.run([
   591→            'ssh', '-i', private_key_path,
   592→            '-o', 'StrictHostKeyChecking=no',
   593→            '-o', 'UserKnownHostsFile=/dev/null',
   594→            f'{username}@{hostname}',
   595→            'chmod +x /tmp/additional_commands.sh && /tmp/additional_commands.sh'
   596→        ], capture_output=True, text=True, timeout=300)  # 5 minute timeout
   597→        
   598→        if result.returncode != 0:
   599→            rich_error(f"Additional commands failed: {result.stderr}")
   600→            return False
   601→        
   602→        rich_success("Additional commands executed successfully")
   603→        return True
   604→        
   605→    except subprocess.TimeoutExpired:
   606→        rich_error("Additional commands execution timed out")
   607→        return False
   608→    except Exception as e:
   609→        rich_error(f"Error executing additional commands: {e}")
   610→        return False
   611→
   612→# =============================================================================
   613→# CORE SPOT INSTANCE MANAGEMENT
   614→# =============================================================================
   615→
   616→def create_simple_security_group(ec2, vpc_id: str) -> str:
   617→    """Create basic security group."""
   618→    try:
   619→        # Check for existing security group
   620→        response = ec2.describe_security_groups(
   621→            Filters=[
   622→                {"Name": "vpc-id", "Values": [vpc_id]},
   623→                {"Name": "group-name", "Values": ["spot-deployer-sg"]},
   624→            ]
   625→        )
   626→        
   627→        if response["SecurityGroups"]:
   628→            return response["SecurityGroups"][0]["GroupId"]
   629→        
   630→        # Create new security group
   631→        response = ec2.create_security_group(
   632→            GroupName="spot-deployer-sg",
   633→            Description="Simple security group for spot instances",
   634→            VpcId=vpc_id
   635→        )
   636→        sg_id = response["GroupId"]
   637→        
   638→        # Add basic rules
   639→        ec2.authorize_security_group_ingress(
   640→            GroupId=sg_id,
   641→            IpPermissions=[
   642→                {
   643→                    "IpProtocol": "tcp",
   644→                    "FromPort": 22,
   645→                    "ToPort": 22,
   646→                    "IpRanges": [{"CidrIp": "0.0.0.0/0"}],
   647→                },
   648→                {
   649→                    "IpProtocol": "tcp", 
   650→                    "FromPort": 4222,
   651→                    "ToPort": 4222,
   652→                    "IpRanges": [{"CidrIp": "0.0.0.0/0"}],
   653→                },
   654→            ]
   655→        )
   656→        
   657→        return sg_id
   658→    except Exception as e:
   659→        print(f"Error creating security group: {e}")
   660→        raise
   661→
   662→def create_instances_in_region(config: SimpleConfig, region: str, count: int, progress=None, task=None) -> List[Dict]:
   663→    """Create spot instances in a specific region."""
   664→    if count <= 0:
   665→        return []
   666→    
   667→    def update_progress(message: str):
   668→        """Update progress bar if available, otherwise use rich_status."""
   669→        if progress and task is not None:
   670→            progress.update(task, description=message)
   671→            time.sleep(0.2)  # Brief pause to show progress
   672→        else:
   673→            rich_status(message)
   674→    
   675→    update_progress(f"🔍 Looking for VPC in {region}...")
   676→    
   677→    try:
   678→        ec2 = boto3.client("ec2", region_name=region)
   679→        
   680→        # Get default VPC
   681→        vpcs = ec2.describe_vpcs(Filters=[{"Name": "is-default", "Values": ["true"]}])
   682→        if not vpcs["Vpcs"]:
   683→            update_progress(f"🔍 No default VPC in {region}, checking all VPCs...")
   684→            # Try any VPC if no default exists
   685→            all_vpcs = ec2.describe_vpcs()
   686→            if all_vpcs["Vpcs"]:
   687→                vpc_id = all_vpcs["Vpcs"][0]["VpcId"]
   688→                update_progress(f"🏗️  Using VPC {vpc_id} in {region}")
   689→            else:
   690→                rich_warning(f"No VPCs found in {region}, skipping")
   691→                return []
   692→        else:
   693→            vpc_id = vpcs["Vpcs"][0]["VpcId"]
   694→            update_progress(f"🏗️  Using default VPC {vpc_id} in {region}")
   695→        
   696→        # Get default subnet
   697→        update_progress(f"🔍 Looking for subnet in VPC {vpc_id}...")
   698→        subnets = ec2.describe_subnets(
   699→            Filters=[
   700→                {"Name": "vpc-id", "Values": [vpc_id]},
   701→                {"Name": "default-for-az", "Values": ["true"]},
   702→            ]
   703→        )
   704→        if not subnets["Subnets"]:
   705→            update_progress(f"🔍 No default subnet in {region}, trying any subnet...")
   706→            # Try any subnet in the VPC
   707→            all_subnets = ec2.describe_subnets(
   708→                Filters=[{"Name": "vpc-id", "Values": [vpc_id]}]
   709→            )
   710→            if all_subnets["Subnets"]:
   711→                subnet_id = all_subnets["Subnets"][0]["SubnetId"]
   712→                update_progress(f"🌐 Using subnet {subnet_id} in {region}")
   713→            else:
   714→                rich_warning(f"No subnets found in VPC {vpc_id}, skipping")
   715→                return []
   716→        else:
   717→            subnet_id = subnets["Subnets"][0]["SubnetId"]
   718→            update_progress(f"🌐 Using default subnet {subnet_id} in {region}")
   719→        
   720→        # Create security group
   721→        update_progress(f"🔒 Creating security group in {region}...")
   722→        sg_id = create_simple_security_group(ec2, vpc_id)
   723→        
   724→        # Get AMI
   725→        update_progress(f"📀 Getting AMI for {region}...")
   726→        ami_id = get_latest_ubuntu_ami(region)
   727→        if not ami_id:
   728→            rich_warning(f"No AMI found for {region}, skipping")
   729→            return []
   730→        
   731→        # Get instance type
   732→        region_config = config.region_config(region)
   733→        instance_type = region_config.get("machine_type", "t3.medium")
   734→        
   735→        # Create user data script
   736→        user_data = f"""#!/bin/bash
   737→apt-get update
   738→apt-get install -y docker.io
   739→systemctl enable docker
   740→systemctl start docker
   741→usermod -aG docker {config.username()}
   742→"""
   743→        
   744→        # Create spot instance request
   745→        update_progress(f"🚀 Requesting spot instances in {region}...")
   746→        spot_request = {
   747→            "ImageId": ami_id,
   748→            "InstanceType": instance_type,
   749→            "SecurityGroupIds": [sg_id],
   750→            "SubnetId": subnet_id,
   751→            "UserData": base64.b64encode(user_data.encode()).decode(),
   752→        }
   753→        
   754→        # Add SSH key if configured
   755→        ssh_key = config.ssh_key_name()
   756→        if ssh_key:
   757→            spot_request["KeyName"] = ssh_key
   758→        
   759→        # Request spot instances
   760→        response = ec2.request_spot_instances(
   761→            InstanceCount=count,
   762→            LaunchSpecification=spot_request,
   763→            Type="one-time"
   764→        )
   765→        
   766→        spot_request_ids = [req["SpotInstanceRequestId"] for req in response["SpotInstanceRequests"]]
   767→        update_progress(f"⏳ Waiting for spot instances to launch in {region}...")
   768→        
   769→        # Wait for fulfillment (simplified - max 5 minutes)
   770→        instances = []
   771→        for attempt in range(30):  # 30 * 10s = 5 minutes max
   772→            try:
   773→                spot_response = ec2.describe_spot_instance_requests(SpotInstanceRequestIds=spot_request_ids)
   774→                
   775→                active_requests = [
   776→                    req for req in spot_response["SpotInstanceRequests"]
   777→                    if req["State"] == "active" and "InstanceId" in req
   778→                ]
   779→                
   780→                if len(active_requests) == count:
   781→                    update_progress(f"🏷️  Tagging instances in {region}...")
   782→                    # Get instance details
   783→                    instance_ids = [req["InstanceId"] for req in active_requests]
   784→                    instance_response = ec2.describe_instances(InstanceIds=instance_ids)
   785→                    
   786→                    for reservation in instance_response["Reservations"]:
   787→                        for instance in reservation["Instances"]:
   788→                            instances.append({
   789→                                "id": instance["InstanceId"],
   790→                                "region": region,
   791→                                "type": instance["InstanceType"],
   792→                                "state": instance["State"]["Name"],
   793→                                "public_ip": instance.get("PublicIpAddress", ""),
   794→                                "private_ip": instance.get("PrivateIpAddress", ""),
   795→                                "created": datetime.now().isoformat(),
   796→                            })
   797→                    
   798→                    # Tag instances
   799→                    if instance_ids:
   800→                        ec2.create_tags(
   801→                            Resources=instance_ids,
   802→                            Tags=[
   803→                                {"Key": "ManagedBy", "Value": "SpotDeployer"},
   804→                                {"Key": "Name", "Value": f"SpotInstance-{region}"},
   805→                            ]
   806→                        )
   807→                    
   808→                    break
   809→                
   810→                # Check for failed requests
   811→                failed = [req for req in spot_response["SpotInstanceRequests"] if req["State"] in ["failed", "cancelled"]]
   812→                if failed:
   813→                    rich_error(f"Some spot requests failed in {region}")
   814→                    break
   815→                
   816→                # Update progress with wait time
   817→                update_progress(f"⏳ Waiting for spot instances to launch in {region}... (attempt {attempt + 1}/30)")
   818→                time.sleep(10)
   819→                
   820→            except Exception as e:
   821→                rich_error(f"Error checking spot requests: {e}")
   822→                break
   823→        
   824→        if not instances:
   825→            rich_warning(f"No instances created in {region} (timeout or failure)")
   826→        
   827→        return instances
   828→        
   829→    except Exception as e:
   830→        rich_error(f"Error creating instances in {region}: {e}")
   831→        return []
   832→
   833→def create_instances_in_region_with_table(config: SimpleConfig, region: str, count: int, creation_status: Dict, log_collector=None, lock=None, live_obj=None, layout_generator=None) -> List[Dict]:
   834→    """Create spot instances in a specific region with live table updates."""
   835→    if count <= 0:
   836→        return []
   837→    
   838→    def update_status(instance_key: str, status: str, instance_id: str = None, ip: str = None, created: str = None):
   839→        """Update the status in the live table."""
   840→        # Sanitize status to remove carriage returns and newlines
   841→        status = status.replace('\r', ' ').replace('\n', ' ').strip()
   842→        
   843→        if lock:
   844→            with lock:
   845→                if instance_key in creation_status:
   846→                    creation_status[instance_key]["status"] = status
   847→                    if instance_id:
   848→                        creation_status[instance_key]["instance_id"] = instance_id
   849→                    if ip:
   850→                        creation_status[instance_key]["public_ip"] = ip
   851→                    if created:
   852→                        creation_status[instance_key]["created"] = created
   853→                # Update live display if available
   854→                if live_obj and layout_generator:
   855→                    live_obj.update(layout_generator())
   856→        else:
   857→            if instance_key in creation_status:
   858→                creation_status[instance_key]["status"] = status
   859→                if instance_id:
   860→                    creation_status[instance_key]["instance_id"] = instance_id
   861→                if ip:
   862→                    creation_status[instance_key]["public_ip"] = ip
   863→                if created:
   864→                    creation_status[instance_key]["created"] = created
   865→            # Update live display if available
   866→            if live_obj and layout_generator:
   867→                live_obj.update(layout_generator())
   868→    
   869→    def log_message(msg: str):
   870→        """Thread-safe logging."""
   871→        if log_collector is not None:
   872→            if lock:
   873→                with lock:
   874→                    log_collector.append(msg)
   875→            else:
   876→                log_collector.append(msg)
   877→    
   878→    # Update all instance keys for this region
   879→    instance_keys = [f"{region}-{i+1}" for i in range(count)]
   880→    
   881→    # Update all instances in this region to show they're starting
   882→    for instance_key in instance_keys:
   883→        update_status(instance_key, "🔍 Looking for VPC...")
   884→    
   885→    try:
   886→        ec2 = boto3.client("ec2", region_name=region)
   887→        
   888→        # Get default VPC
   889→        log_message(f"[{region}] Looking for VPC...")
   890→        time.sleep(0.2)
   891→        vpcs = ec2.describe_vpcs(Filters=[{"Name": "is-default", "Values": ["true"]}])
   892→        if not vpcs["Vpcs"]:
   893→            for instance_key in instance_keys:
   894→                update_status(instance_key, "🔍 No default VPC, checking all VPCs...")
   895→            log_message(f"[{region}] No default VPC, checking all VPCs...")
   896→            time.sleep(0.2)
   897→            all_vpcs = ec2.describe_vpcs()
   898→            if all_vpcs["Vpcs"]:
   899→                vpc_id = all_vpcs["Vpcs"][0]["VpcId"]
   900→                for instance_key in instance_keys:
   901→                    update_status(instance_key, f"🏗️ Using VPC {vpc_id}")
   902→                log_message(f"[{region}] Using VPC {vpc_id}")
   903→            else:
   904→                for instance_key in instance_keys:
   905→                    update_status(instance_key, "❌ No VPCs found")
   906→                log_message(f"[{region}] ❌ No VPCs found")
   907→                return []
   908→        else:
   909→            vpc_id = vpcs["Vpcs"][0]["VpcId"]
   910→            for instance_key in instance_keys:
   911→                update_status(instance_key, f"🏗️ Using default VPC {vpc_id}")
   912→            log_message(f"[{region}] Using default VPC {vpc_id}")
   913→        
   914→        time.sleep(0.2)
   915→        
   916→        # Get default subnet
   917→        for instance_key in instance_keys:
   918→            update_status(instance_key, "🔍 Looking for subnet...")
   919→        time.sleep(0.5)
   920→        subnets = ec2.describe_subnets(
   921→            Filters=[
   922→                {"Name": "vpc-id", "Values": [vpc_id]},
   923→                {"Name": "default-for-az", "Values": ["true"]},
   924→            ]
   925→        )
   926→        if not subnets["Subnets"]:
   927→            for instance_key in instance_keys:
   928→                update_status(instance_key, "🔍 No default subnet, trying any...")
   929→            time.sleep(0.5)
   930→            all_subnets = ec2.describe_subnets(
   931→                Filters=[{"Name": "vpc-id", "Values": [vpc_id]}]
   932→            )
   933→            if all_subnets["Subnets"]:
   934→                subnet_id = all_subnets["Subnets"][0]["SubnetId"]
   935→                for instance_key in instance_keys:
   936→                    update_status(instance_key, f"🌐 Using subnet {subnet_id}")
   937→            else:
   938→                for instance_key in instance_keys:
   939→                    update_status(instance_key, "❌ No subnets found")
   940→                return []
   941→        else:
   942→            subnet_id = subnets["Subnets"][0]["SubnetId"]
   943→            for instance_key in instance_keys:
   944→                update_status(instance_key, f"🌐 Using default subnet {subnet_id}")
   945→        
   946→        time.sleep(0.5)
   947→        
   948→        # Create security group
   949→        for instance_key in instance_keys:
   950→            update_status(instance_key, "🔒 Creating security group...")
   951→        log_message(f"[{region}] Creating security group...")
   952→        time.sleep(0.2)
   953→        sg_id = create_simple_security_group(ec2, vpc_id)
   954→        
   955→        # Get AMI
   956→        for instance_key in instance_keys:
   957→            update_status(instance_key, "📀 Getting AMI...")
   958→        log_message(f"[{region}] Getting AMI...")
   959→        time.sleep(0.2)
   960→        ami_id = get_latest_ubuntu_ami(region, log_message)
   961→        if not ami_id:
   962→            for instance_key in instance_keys:
   963→                update_status(instance_key, "❌ No AMI found")
   964→            log_message(f"[{region}] ❌ No AMI found")
   965→            return []
   966→        
   967→        # Get instance type
   968→        region_config = config.region_config(region)
   969→        instance_type = region_config.get("machine_type", "t3.medium")
   970→        for instance_key in instance_keys:
   971→            creation_status[instance_key]["type"] = instance_type
   972→        
   973→        # Generate minimal cloud-init script
   974→        log_message(f"[{region}] Generating minimal cloud-init script...")
   975→        user_data = generate_minimal_cloud_init(config)
   976→        
   977→        # Create spot instance request
   978→        for instance_key in instance_keys:
   979→            update_status(instance_key, f"🚀 Requesting spot instance...")
   980→        log_message(f"[{region}] Requesting {count} spot instance(s)...")
   981→        time.sleep(0.2)
   982→        
   983→        # Build security groups list
   984→        security_groups = [sg_id]
   985→        additional_sgs = config.security_groups()
   986→        if additional_sgs:
   987→            security_groups.extend(additional_sgs)
   988→        
   989→        # Build block device mappings for storage (commented out to test)
   990→        # block_device_mappings = [
   991→        #     {
   992→        #         "DeviceName": "/dev/sda1",
   993→        #         "Ebs": {
   994→        #             "VolumeSize": config.instance_storage_gb(),
   995→        #             "VolumeType": "gp3",
   996→        #             "DeleteOnTermination": True
   997→        #         }
   998→        #     }
   999→        # ]
  1000→        
  1001→        spot_request = {
  1002→            "ImageId": ami_id,
  1003→            "InstanceType": instance_type,
  1004→            "SecurityGroupIds": security_groups,
  1005→            "SubnetId": subnet_id,
  1006→            "UserData": base64.b64encode(user_data.encode()).decode(),
  1007→            # "BlockDeviceMappings": block_device_mappings,
  1008→        }
  1009→        
  1010→        # Add SSH key if configured
  1011→        ssh_key = config.ssh_key_name()
  1012→        if ssh_key:
  1013→            spot_request["KeyName"] = ssh_key
  1014→        
  1015→        # Add associate public IP if configured (commented out to test)
  1016→        # if config.associate_public_ip():
  1017→        #     spot_request["AssociatePublicIpAddress"] = True
  1018→        
  1019→        # Build spot instance request parameters
  1020→        spot_params = {
  1021→            "InstanceCount": count,
  1022→            "LaunchSpecification": spot_request,
  1023→            "Type": "one-time"
  1024→        }
  1025→        
  1026→        # Add spot price if configured
  1027→        region_config = config.region_config(region)
  1028→        spot_price = region_config.get("spot_price_limit") or config.spot_price_limit()
  1029→        if spot_price:
  1030→            spot_params["SpotPrice"] = str(spot_price)
  1031→        
  1032→        # Request spot instances
  1033→        response = ec2.request_spot_instances(**spot_params)
  1034→        
  1035→        spot_request_ids = [req["SpotInstanceRequestId"] for req in response["SpotInstanceRequests"]]
  1036→        for instance_key in instance_keys:
  1037→            update_status(instance_key, "⏳ Waiting for spot instance to launch...")
  1038→        log_message(f"[{region}] Waiting for {count} spot instance(s) to launch...")
  1039→        
  1040→        # Wait for fulfillment (simplified - max 5 minutes)
  1041→        instances = []
  1042→        for attempt in range(30):  # 30 * 10s = 5 minutes max
  1043→            try:
  1044→                spot_response = ec2.describe_spot_instance_requests(SpotInstanceRequestIds=spot_request_ids)
  1045→                
  1046→                active_requests = [
  1047→                    req for req in spot_response["SpotInstanceRequests"]
  1048→                    if req["State"] == "active" and "InstanceId" in req
  1049→                ]
  1050→                
  1051→                if len(active_requests) == count:
  1052→                    for instance_key in instance_keys:
  1053→                        update_status(instance_key, "🏷️ Getting instance details...")
  1054→                    log_message(f"[{region}] Getting instance details...")
  1055→                    time.sleep(0.2)
  1056→                    # Get instance details
  1057→                    instance_ids = [req["InstanceId"] for req in active_requests]
  1058→                    instance_response = ec2.describe_instances(InstanceIds=instance_ids)
  1059→                    
  1060→                    instance_idx = 0
  1061→                    for reservation in instance_response["Reservations"]:
  1062→                        for instance in reservation["Instances"]:
  1063→                            instance_id = instance["InstanceId"]
  1064→                            public_ip = instance.get("PublicIpAddress", "pending...")
  1065→                            created_time = datetime.now().strftime('%m-%d %H:%M')
  1066→                            
  1067→                            instances.append({
  1068→                                "id": instance_id,
  1069→                                "region": region,
  1070→                                "type": instance["InstanceType"],
  1071→                                "state": instance["State"]["Name"],
  1072→                                "public_ip": public_ip,
  1073→                                "private_ip": instance.get("PrivateIpAddress", ""),
  1074→                                "created": datetime.now().isoformat(),
  1075→                            })
  1076→                            
  1077→                            # Update the corresponding instance key
  1078→                            if instance_idx < len(instance_keys):
  1079→                                update_status(instance_keys[instance_idx], "✅ Instance created successfully", 
  1080→                                            instance_id, public_ip, created_time)
  1081→                                instance_idx += 1
  1082→                    
  1083→                    # Tag instances with comprehensive tags
  1084→                    if instance_ids:
  1085→                        # Build tag list
  1086→                        tags = [
  1087→                            {"Key": "ManagedBy", "Value": "SpotDeployer"},
  1088→                            {"Key": "Name", "Value": f"SpotInstance-{region}"},
  1089→                            {"Key": "Region", "Value": region},
  1090→                            {"Key": "CreatedBy", "Value": "AWS-Spot-Deployer"},
  1091→                            {"Key": "CreatedAt", "Value": datetime.now().strftime('%Y-%m-%d %H:%M:%S')},
  1092→                        ]
  1093→                        
  1094→                        # Add global tags from config
  1095→                        global_tags = config.tags()
  1096→                        for key, value in global_tags.items():
  1097→                            tags.append({"Key": key, "Value": value})
  1098→                        
  1099→                        # Add region-specific tags
  1100→                        region_tags = region_config.get("tags", {})
  1101→                        for key, value in region_tags.items():
  1102→                            tags.append({"Key": key, "Value": value})
  1103→                        
  1104→                        ec2.create_tags(Resources=instance_ids, Tags=tags)
  1105→                    
  1106→                    break
  1107→                
  1108→                # Check for failed requests
  1109→                failed = [req for req in spot_response["SpotInstanceRequests"] if req["State"] in ["failed", "cancelled"]]
  1110→                if failed:
  1111→                    for instance_key in instance_keys:
  1112→                        update_status(instance_key, "❌ Spot request failed")
  1113→                    break
  1114→                
  1115→                # Update progress with wait time
  1116→                for instance_key in instance_keys:
  1117→                    update_status(instance_key, f"⏳ Waiting for spot instance... (attempt {attempt + 1}/30)")
  1118→                time.sleep(10)
  1119→                
  1120→            except Exception as e:
  1121→                for instance_key in instance_keys:
  1122→                    update_status(instance_key, f"❌ Error: {str(e)[:30]}...")
  1123→                break
  1124→        
  1125→        if not instances:
  1126→            for instance_key in instance_keys:
  1127→                update_status(instance_key, "❌ No instances created (timeout)")
  1128→        
  1129→        return instances
  1130→        
  1131→    except Exception as e:
  1132→        for instance_key in instance_keys:
  1133→            update_status(instance_key, f"❌ Error: {str(e)[:30]}...")
  1134→        return []
  1135→
  1136→# =============================================================================
  1137→# MAIN COMMANDS
  1138→# =============================================================================
  1139→
  1140→def cmd_create(config: SimpleConfig, state: SimpleStateManager) -> None:
  1141→    """Create spot instances across configured regions."""
  1142→    if not check_aws_auth():
  1143→        return
  1144→    
  1145→    regions = config.regions()
  1146→    total_count = config.instance_count()
  1147→    
  1148→    if not regions:
  1149→        rich_error("No regions configured. Run 'setup' first.")
  1150→        return
  1151→    
  1152→    instances_per_region = max(1, total_count // len(regions))
  1153→    
  1154→    if RICH_AVAILABLE and console:
  1155→        # Create log collector and status tracker
  1156→        log_messages = []
  1157→        creation_status = {}
  1158→        all_instances = []
  1159→        active_threads = []
  1160→        completed_count = 0
  1161→        
  1162→        # Support up to 10 instances max with better distribution
  1163→        max_instances = min(total_count, 10)
  1164→        instances_per_region = max(1, max_instances // len(regions))
  1165→        
  1166→        # Calculate remaining instances for the last region
  1167→        remaining_instances = max_instances % len(regions)
  1168→        
  1169→        # Initialize status for each instance
  1170→        instance_counter = 0
  1171→        for region_idx, region in enumerate(regions):
  1172→            instances_for_this_region = instances_per_region
  1173→            if region_idx == len(regions) - 1:  # Last region gets remaining instances
  1174→                instances_for_this_region += remaining_instances
  1175→            
  1176→            for i in range(instances_for_this_region):
  1177→                if instance_counter >= max_instances:
  1178→                    break
  1179→                key = f"{region}-{i+1}"
  1180→                creation_status[key] = {
  1181→                    "region": region,
  1182→                    "instance_id": "pending...",
  1183→                    "status": "⏳ Waiting to start",
  1184→                    "type": "t3.medium",
  1185→                    "public_ip": "pending...",
  1186→                    "created": "pending..."
  1187→                }
  1188→                instance_counter += 1
  1189→        
  1190→        # Create thread-safe lock
  1191→        lock = threading.Lock()
  1192→        
  1193→        def generate_layout():
  1194→            # Create the table with fixed widths
  1195→            table = Table(title=f"Creating {len(creation_status)} instances across {len(regions)} regions", show_header=True, width=120)
  1196→            table.add_column("Region", style="magenta", width=12, no_wrap=True)
  1197→            table.add_column("Instance ID", style="cyan", width=20, no_wrap=True)
  1198→            table.add_column("Status", style="yellow", width=40, no_wrap=True)
  1199→            table.add_column("Type", style="green", width=12, no_wrap=True)
  1200→            table.add_column("Public IP", style="blue", width=16, no_wrap=True)
  1201→            table.add_column("Created", style="dim", width=12, no_wrap=True)
  1202→            
  1203→            # Sort: active work at top, completed at bottom
  1204→            sorted_items = sorted(creation_status.items(), key=lambda x: (
  1205→                0 if x[1]["status"].startswith("✅") else 1,  # Completed items last
  1206→                1 if x[1]["status"].startswith("❌") else 0,  # Failed items first
  1207→                2 if x[1]["status"].startswith("⏳") else 0,  # Waiting items last
  1208→                x[0]  # Then by key
  1209→            ))
  1210→            
  1211→            for key, item in sorted_items:
  1212→                # Add status indicators and truncate if needed
  1213→                status = item["status"]
  1214→                if len(status) > 38:  # Leave room for styling
  1215→                    status = status[:35] + "..."
  1216→                
  1217→                if status.startswith("✅"):
  1218→                    status_style = "[bold green]" + status + "[/bold green]"
  1219→                elif status.startswith("❌"):
  1220→                    status_style = "[bold red]" + status + "[/bold red]"
  1221→                elif status.startswith("🔍") or status.startswith("🏗️") or status.startswith("🌐"):
  1222→                    status_style = "[bold blue]" + status + "[/bold blue]"
  1223→                elif status.startswith("🚀") or status.startswith("⏳"):
  1224→                    status_style = "[bold yellow]" + status + "[/bold yellow]"
  1225→                else:
  1226→                    status_style = status
  1227→                
  1228→                # Truncate other fields if needed
  1229→                region = item["region"][:11] if len(item["region"]) > 11 else item["region"]
  1230→                instance_id = item["instance_id"][:19] if len(item["instance_id"]) > 19 else item["instance_id"]
  1231→                instance_type = item["type"][:11] if len(item["type"]) > 11 else item["type"]
  1232→                public_ip = item["public_ip"][:15] if len(item["public_ip"]) > 15 else item["public_ip"]
  1233→                created = item["created"][:11] if len(item["created"]) > 11 else item["created"]
  1234→                
  1235→                table.add_row(
  1236→                    region,
  1237→                    instance_id,
  1238→                    status_style,
  1239→                    instance_type,
  1240→                    public_ip,
  1241→                    created
  1242→                )
  1243→            
  1244→            # Create the log panel
  1245→            log_content = "\n".join(log_messages[-20:])  # Show last 20 log messages
  1246→            if not log_content.strip():
  1247→                log_content = "🚀 Initializing..."
  1248→            
  1249→            log_panel = Panel(
  1250→                log_content,
  1251→                title=f"📋 Log Messages ({len(log_messages)} total)",
  1252→                border_style="blue",
  1253→                height=12
  1254→            )
  1255→            
  1256→            # Create layout
  1257→            layout = Layout()
  1258→            layout.split_column(
  1259→                Layout(table, name="table", ratio=2),
  1260→                Layout(log_panel, name="logs", ratio=1)
  1261→            )
  1262→            
  1263→            return layout
  1264→        
  1265→        def post_creation_setup(instances, config, creation_status, log_messages, lock, live_obj, generate_layout):
  1266→            """Handle post-creation setup: file uploads and script execution."""
  1267→            private_key_path = config.private_ssh_key_path()
  1268→            username = config.username()
  1269→            
  1270→            for instance in instances:
  1271→                instance_id = instance['id']
  1272→                hostname = instance.get('public_ip', instance.get('private_ip', ''))
  1273→                region = instance['region']
  1274→                
  1275→                # Find the instance key for status updates
  1276→                instance_key = None
  1277→                for key in creation_status.keys():
  1278→                    if key.startswith(f"{region}-"):
  1279→                        instance_key = key
  1280→                        break
  1281→                
  1282→                if not instance_key or not hostname:
  1283→                    continue
  1284→                
  1285→                try:
  1286→                    # Update status to waiting for SSH
  1287→                    def update_status(status):
  1288→                        if lock:
  1289→                            with lock:
  1290→                                creation_status[instance_key]["status"] = status
  1291→                                live_obj.update(generate_layout())
  1292→                        else:
  1293→                            creation_status[instance_key]["status"] = status
  1294→                            live_obj.update(generate_layout())
  1295→                    
  1296→                    def log_message(msg):
  1297→                        if lock:
  1298→                            with lock:
  1299→                                log_messages.append(msg)
  1300→                                live_obj.update(generate_layout())
  1301→                        else:
  1302→                            log_messages.append(msg)
  1303→                            live_obj.update(generate_layout())
  1304→                    
  1305→                    # Wait for SSH to be ready
  1306→                    update_status("⏳ Waiting for SSH...")
  1307→                    log_message(f"[{region}] Waiting for SSH on {hostname}...")
  1308→                    
  1309→                    if not wait_for_ssh_ready(hostname, username, private_key_path, timeout=300):
  1310→                        update_status("❌ SSH timeout")
  1311→                        log_message(f"[{region}] SSH timeout on {hostname}")
  1312→                        continue
  1313→                    
  1314→                    # Upload files
  1315→                    update_status("📤 Uploading files...")
  1316→                    log_message(f"[{region}] Uploading files to {hostname}...")
  1317→                    
  1318→                    if not upload_files_to_instance(hostname, username, private_key_path, config):
  1319→                        update_status("❌ Upload failed")
  1320→                        log_message(f"[{region}] File upload failed on {hostname}")
  1321→                        continue
  1322→                    
  1323→                    # Execute startup script
  1324→                    update_status("🚀 Running startup script...")
  1325→                    log_message(f"[{region}] Executing startup script on {hostname}...")
  1326→                    
  1327→                    if not execute_startup_script(hostname, username, private_key_path, config):
  1328→                        update_status("❌ Startup script failed")
  1329→                        log_message(f"[{region}] Startup script failed on {hostname}")
  1330→                        continue
  1331→                    
  1332→                    # Execute additional commands
  1333→                    update_status("🔧 Running additional commands...")
  1334→                    log_message(f"[{region}] Executing additional commands on {hostname}...")
  1335→                    
  1336→                    if not execute_additional_commands(hostname, username, private_key_path, config):
  1337→                        update_status("❌ Additional commands failed")
  1338→                        log_message(f"[{region}] Additional commands failed on {hostname}")
  1339→                        continue
  1340→                    
  1341→                    # Success
  1342→                    update_status("✅ Setup complete")
  1343→                    log_message(f"[{region}] Setup completed successfully on {hostname}")
  1344→                    
  1345→                except Exception as e:
  1346→                    if instance_key:
  1347→                        if lock:
  1348→                            with lock:
  1349→                                creation_status[instance_key]["status"] = f"❌ Setup error: {str(e)[:20]}..."
  1350→                                live_obj.update(generate_layout())
  1351→                        else:
  1352→                            creation_status[instance_key]["status"] = f"❌ Setup error: {str(e)[:20]}..."
  1353→                            live_obj.update(generate_layout())
  1354→                    
  1355→                    log_message(f"[{region}] Setup error on {hostname}: {str(e)}")
  1356→
  1357→        def create_region_instances(region, instances_count, live_obj):
  1358→            """Thread function to create instances in a specific region."""
  1359→            try:
  1360→                with lock:
  1361→                    log_messages.append(f"🚀 [{region}] Starting creation of {instances_count} instance(s)...")
  1362→                    live_obj.update(generate_layout())
  1363→                
  1364→                # Add a small delay to make the status update visible
  1365→                time.sleep(1)
  1366→                
  1367→                instances = create_instances_in_region_with_table(config, region, instances_count, creation_status, log_messages, lock, live_obj, generate_layout)
  1368→                
  1369→                with lock:
  1370→                    all_instances.extend(instances)
  1371→                    for instance in instances:
  1372→                        log_messages.append(f"✅ [{region}] Instance {instance['id']} created successfully!")
  1373→                    live_obj.update(generate_layout())
  1374→                
  1375→                # Post-creation: Upload files and execute scripts
  1376→                if instances and config.private_ssh_key_path():
  1377→                    with lock:
  1378→                        log_messages.append(f"🔄 [{region}] Starting post-creation setup...")
  1379→                        live_obj.update(generate_layout())
  1380→                    
  1381→                    post_creation_setup(instances, config, creation_status, log_messages, lock, live_obj, generate_layout)
  1382→                        
  1383→            except Exception as e:
  1384→                with lock:
  1385→                    log_messages.append(f"❌ [{region}] Error: {str(e)}")
  1386→                    live_obj.update(generate_layout())
  1387→        
  1388→        # Initialize log
  1389→        log_messages.append("🚀 Starting instance creation process...")
  1390→        log_messages.append(f"📊 Creating {len(creation_status)} instances across {len(regions)} regions")
  1391→        
  1392→        # Print initial status
  1393→        rich_status(f"Starting creation of {len(creation_status)} instances across {len(regions)} regions...")
  1394→        
  1395→        # Test the update mechanism first
  1396→        with lock:
  1397→            log_messages.append("🔧 Testing update mechanism...")
  1398→            for key in creation_status:
  1399→                creation_status[key]["status"] = "🔧 Testing updates..."
  1400→        
  1401→        # Start live display (try without screen mode for better compatibility)
  1402→        with Live(generate_layout(), refresh_per_second=4, console=console, screen=False) as live:
  1403→            # Test update
  1404→            time.sleep(2)
  1405→            live.update(generate_layout())
  1406→            
  1407→            # Start threads for each region (up to 10 instances total)
  1408→            for region_idx, region in enumerate(regions):
  1409→                if len(active_threads) >= 10:  # Max 10 threads
  1410→                    break
  1411→                
  1412→                # Calculate instances for this region
  1413→                instances_for_this_region = instances_per_region
  1414→                if region_idx == len(regions) - 1:  # Last region gets remaining instances
  1415→                    instances_for_this_region += remaining_instances
  1416→                    
  1417→                thread = threading.Thread(target=create_region_instances, args=(region, instances_for_this_region, live))
  1418→                thread.daemon = True
  1419→                active_threads.append(thread)
  1420→                thread.start()
  1421→                
  1422→                with lock:
  1423→                    log_messages.append(f"🚀 Started creation thread for {region} ({instances_for_this_region} instance(s))")
  1424→                
  1425→                time.sleep(0.5)  # Small delay between thread starts for visibility
  1426→                live.update(generate_layout())
  1427→            
  1428→            # Wait for all threads to complete
  1429→            with lock:
  1430→                log_messages.append("⏳ Waiting for all instances to complete...")
  1431→            live.update(generate_layout())
  1432→            
  1433→            for thread in active_threads:
  1434→                thread.join()
  1435→                live.update(generate_layout())
  1436→            
  1437→            # Save all instances to state
  1438→            total_created = 0
  1439→            for instance in all_instances:
  1440→                state.add_instance(instance)
  1441→                total_created += 1
  1442→            
  1443→            with lock:
  1444→                log_messages.append(f"💾 Saved {total_created} instances to state")
  1445→                log_messages.append("✅ All instances created successfully!")
  1446→            
  1447→            # Final display update
  1448→            time.sleep(2)
  1449→        
  1450→        # Show final results table
  1451→        console.print("\n")
  1452→        rich_success(f"Successfully created {total_created} instances!")
  1453→        
  1454→        if total_created > 0:
  1455→            console.print("\n")
  1456→            cmd_list(state)  # Show the final table
  1457→    else:
  1458→        # Fallback without table
  1459→        total_created = 0
  1460→        for region in regions:
  1461→            instances = create_instances_in_region(config, region, instances_per_region)
  1462→            for instance in instances:
  1463→                state.add_instance(instance)
  1464→                total_created += 1
  1465→                rich_success(f"Created {instance['id']} in {region}")
  1466→    
  1467→    rich_success(f"Successfully created {total_created} instances")
  1468→
  1469→def cmd_list(state: SimpleStateManager) -> None:
  1470→    """List all managed instances with Rich table."""
  1471→    if not check_aws_auth():
  1472→        return
  1473→    
  1474→    instances = state.load_instances()
  1475→    
  1476→    if not instances:
  1477→        rich_status("No instances found")
  1478→        return
  1479→    
  1480→    if RICH_AVAILABLE and console:
  1481→        # Create beautiful Rich table with consistent widths
  1482→        table = Table(title=f"Managed Instances ({len(instances)} total)", show_header=True, width=120)
  1483→        table.add_column("Instance ID", style="cyan", width=20, no_wrap=True)
  1484→        table.add_column("Region", style="magenta", width=12, no_wrap=True)
  1485→        table.add_column("Type", style="green", width=12, no_wrap=True)
  1486→        table.add_column("State", style="yellow", width=12, no_wrap=True)
  1487→        table.add_column("Public IP", style="blue", width=16, no_wrap=True)
  1488→        table.add_column("Created", style="dim", width=12, no_wrap=True)
  1489→        
  1490→        for instance in instances:
  1491→            # Format creation time
  1492→            created = instance.get('created', 'Unknown')
  1493→            if created != 'Unknown':
  1494→                try:
  1495→                    created_dt = datetime.fromisoformat(created.replace('Z', '+00:00'))
  1496→                    created = created_dt.strftime('%m-%d %H:%M')
  1497→                except:
  1498→                    created = 'Unknown'
  1499→            
  1500→            # Style state column
  1501→            state_text = instance.get('state', 'unknown')
  1502→            if state_text == 'running':
  1503→                state_style = "[bold green]running[/bold green]"
  1504→            elif state_text == 'pending':
  1505→                state_style = "[bold yellow]pending[/bold yellow]"
  1506→            elif state_text in ['stopped', 'terminated']:
  1507→                state_style = "[bold red]" + state_text + "[/bold red]"
  1508→            else:
  1509→                state_style = state_text
  1510→            
  1511→            table.add_row(
  1512→                instance['id'],
  1513→                instance['region'],
  1514→                instance['type'],
  1515→                state_style,
  1516→                instance.get('public_ip', 'N/A'),
  1517→                created
  1518→            )
  1519→        
  1520→        console.print(table)
  1521→    else:
  1522→        # Fallback to simple table
  1523→        print(f"\nManaged Instances ({len(instances)} total):")
  1524→        print("-" * 90)
  1525→        print(f"{'ID':<20} {'Region':<15} {'Type':<12} {'State':<10} {'Public IP':<15} {'Created':<16}")
  1526→        print("-" * 90)
  1527→        
  1528→        for instance in instances:
  1529→            created = instance.get('created', 'Unknown')
  1530→            if created != 'Unknown':
  1531→                try:
  1532→                    created_dt = datetime.fromisoformat(created.replace('Z', '+00:00'))
  1533→                    created = created_dt.strftime('%m-%d %H:%M')
  1534→                except:
  1535→                    created = 'Unknown'
  1536→            
  1537→            print(f"{instance['id']:<20} {instance['region']:<15} {instance['type']:<12} "
  1538→                  f"{instance['state']:<10} {instance.get('public_ip', 'N/A'):<15} {created:<16}")
  1539→
  1540→def cmd_destroy(state: SimpleStateManager) -> None:
  1541→    """Destroy all managed instances and clean up all created resources."""
  1542→    if not check_aws_auth():
  1543→        return
  1544→    
  1545→    instances = state.load_instances()
  1546→    
  1547→    if not instances:
  1548→        rich_status("No instances to destroy")
  1549→        # Still try to clean up any orphaned VPCs
  1550→        _cleanup_vpcs()
  1551→        return
  1552→    
  1553→    if RICH_AVAILABLE and console:
  1554→        # Clear screen and set up layout
  1555→        console.clear()
  1556→        
  1557→        # Create log collector
  1558→        log_messages = []
  1559→        
  1560→        # Create live-updating table for destruction progress
  1561→        destruction_status = {}
  1562→        for instance in instances:
  1563→            key = instance["id"]
  1564→            destruction_status[key] = {
  1565→                "region": instance["region"],
  1566→                "instance_id": instance["id"],
  1567→                "status": "🔄 Terminating...",
  1568→                "type": instance["type"],
  1569→                "public_ip": instance.get("public_ip", "N/A"),
  1570→                "created": instance.get("created", "Unknown")
  1571→            }
  1572→        
  1573→        def generate_destroy_layout():
  1574→            # Create the table
  1575→            table = Table(title=f"Destroying {len(instances)} instances", show_header=True)
  1576→            table.add_column("Region", style="magenta", width=12)
  1577→            table.add_column("Instance ID", style="cyan", width=20)
  1578→            table.add_column("Status", style="yellow", width=25)
  1579→            table.add_column("Type", style="green", width=10)
  1580→            table.add_column("Public IP", style="blue", width=15)
  1581→            table.add_column("Created", style="dim", width=12)
  1582→            
  1583→            # Sort: active work at top, completed at bottom
  1584→            sorted_items = sorted(destruction_status.items(), key=lambda x: (
  1585→                0 if x[1]["status"].startswith("✅") else 1,  # Completed items last
  1586→                1 if x[1]["status"].startswith("❌") else 0,  # Failed items first
  1587→                x[0]  # Then by key
  1588→            ))
  1589→            
  1590→            for key, item in sorted_items:
  1591→                # Format created time
  1592→                created = item["created"]
  1593→                if created and created != "Unknown":
  1594→                    try:
  1595→                        created_dt = datetime.fromisoformat(created.replace('Z', '+00:00'))
  1596→                        created = created_dt.strftime('%m-%d %H:%M')
  1597→                    except:
  1598→                        created = "Unknown"
  1599→                
  1600→                table.add_row(
  1601→                    item["region"],
  1602→                    item["instance_id"],
  1603→                    item["status"],
  1604→                    item["type"],
  1605→                    item["public_ip"],
  1606→                    created
  1607→                )
  1608→            
  1609→            # Create the log panel
  1610→            log_content = "\n".join(log_messages[-20:])  # Show last 20 log messages
  1611→            log_panel = Panel(
  1612→                log_content,
  1613→                title="📋 Log Messages",
  1614→                border_style="blue",
  1615→                height=8
  1616→            )
  1617→            
  1618→            # Create layout
  1619→            layout = Layout()
  1620→            layout.split_column(
  1621→                Layout(table, name="table", ratio=3),
  1622→                Layout(log_panel, name="logs", ratio=1)
  1623→            )
  1624→            
  1625→            return layout
  1626→        
  1627→        # Group by region
  1628→        by_region = {}
  1629→        for instance in instances:
  1630→            region = instance["region"]
  1631→            if region not in by_region:
  1632→                by_region[region] = []
  1633→            by_region[region].append(instance)
  1634→        
  1635→        with Live(generate_destroy_layout(), refresh_per_second=2, console=console, screen=True):
  1636→            total_terminated = 0
  1637→            for region, region_instances in by_region.items():
  1638→                try:
  1639→                    log_messages.append(f"Terminating {len(region_instances)} instances in {region}...")
  1640→                    ec2 = boto3.client("ec2", region_name=region)
  1641→                    instance_ids = [inst["id"] for inst in region_instances]
  1642→                    
  1643→                    # Update status for all instances in this region
  1644→                    for instance in region_instances:
  1645→                        destruction_status[instance["id"]]["status"] = "🔄 Terminating..."
  1646→                    
  1647→                    time.sleep(1)  # Show the terminating status
  1648→                    
  1649→                    # Terminate instances
  1650→                    ec2.terminate_instances(InstanceIds=instance_ids)
  1651→                    log_messages.append(f"Successfully terminated {len(instance_ids)} instances in {region}")
  1652→                    
  1653→                    # Update status to completed
  1654→                    for instance in region_instances:
  1655→                        destruction_status[instance["id"]]["status"] = "✅ Terminated"
  1656→                    
  1657→                    removed = state.remove_instances_by_region(region)
  1658→                    total_terminated += removed
  1659→                    
  1660→                    time.sleep(1)  # Show the completed status
  1661→                    
  1662→                except Exception as e:
  1663→                    log_messages.append(f"Error terminating instances in {region}: {e}")
  1664→                    # Update status to failed
  1665→                    for instance in region_instances:
  1666→                        destruction_status[instance["id"]]["status"] = f"❌ Error: {str(e)[:15]}..."
  1667→                    
  1668→                    time.sleep(1)  # Show the error status
  1669→            
  1670→            # Final update
  1671→            time.sleep(2)
  1672→    else:
  1673→        # Fallback without table
  1674→        by_region = {}
  1675→        for instance in instances:
  1676→            region = instance["region"]
  1677→            if region not in by_region:
  1678→                by_region[region] = []
  1679→            by_region[region].append(instance["id"])
  1680→        
  1681→        total_terminated = 0
  1682→        for region, instance_ids in by_region.items():
  1683→            try:
  1684→                ec2 = boto3.client("ec2", region_name=region)
  1685→                ec2.terminate_instances(InstanceIds=instance_ids)
  1686→                removed = state.remove_instances_by_region(region)
  1687→                total_terminated += removed
  1688→                rich_success(f"Terminated {len(instance_ids)} instances in {region}")
  1689→            except Exception as e:
  1690→                rich_error(f"Error terminating instances in {region}: {e}")
  1691→    
  1692→    rich_success(f"Successfully terminated {total_terminated} instances")
  1693→    
  1694→    # Clean up VPCs and other resources
  1695→    _cleanup_vpcs()
  1696→
  1697→def _cleanup_vpcs() -> None:
  1698→    """Clean up VPCs and other resources created by this tool."""
  1699→    rich_status("Cleaning up VPCs and other resources...")
  1700→    
  1701→    # Get regions from config
  1702→    config = SimpleConfig()
  1703→    regions = config.regions()
  1704→    
  1705→    if not regions:
  1706→        rich_warning("No regions configured for cleanup")
  1707→        return
  1708→    
  1709→    if RICH_AVAILABLE and console:
  1710→        with Progress(
  1711→            SpinnerColumn(),
  1712→            TextColumn("[progress.description]{task.description}"),
  1713→            console=console,
  1714→            transient=True
  1715→        ) as progress:
  1716→            total_cleaned = 0
  1717→            for region in regions:
  1718→                task = progress.add_task(f"Scanning VPCs in {region}...", total=None)
  1719→                try:
  1720→                    ec2 = boto3.client("ec2", region_name=region)
  1721→                    
  1722→                    # Find VPCs with SpotDeployer tags
  1723→                    vpcs = ec2.describe_vpcs(
  1724→                        Filters=[
  1725→                            {"Name": "tag:ManagedBy", "Values": ["SpotDeployer"]},
  1726→                        ]
  1727→                    )
  1728→                    
  1729→                    for vpc in vpcs["Vpcs"]:
  1730→                        vpc_id = vpc["VpcId"]
  1731→                        progress.update(task, description=f"Cleaning VPC {vpc_id} in {region}...")
  1732→                        try:
  1733→                            # Check if VPC has any instances
  1734→                            instances = ec2.describe_instances(
  1735→                                Filters=[{"Name": "vpc-id", "Values": [vpc_id]}]
  1736→                            )
  1737→                            
  1738→                            has_running_instances = any(
  1739→                                instance["State"]["Name"] not in ["terminated", "shutting-down"]
  1740→                                for reservation in instances["Reservations"]
  1741→                                for instance in reservation["Instances"]
  1742→                            )
  1743→                            
  1744→                            if has_running_instances:
  1745→                                progress.remove_task(task)
  1746→                                rich_warning(f"VPC {vpc_id} in {region} has running instances, skipping")
  1747→                                task = progress.add_task(f"Scanning VPCs in {region}...", total=None)
  1748→                                continue
  1749→                            
  1750→                            # Try basic cleanup
  1751→                            # Delete security groups (except default)
  1752→                            sgs = ec2.describe_security_groups(
  1753→                                Filters=[{"Name": "vpc-id", "Values": [vpc_id]}]
  1754→                            )
  1755→                            for sg in sgs["SecurityGroups"]:
  1756→                                if sg["GroupName"] != "default":
  1757→                                    try:
  1758→                                        ec2.delete_security_group(GroupId=sg["GroupId"])
  1759→                                    except Exception:
  1760→                                        pass  # May fail due to dependencies
  1761→                            
  1762→                            # Delete subnets
  1763→                            subnets = ec2.describe_subnets(
  1764→                                Filters=[{"Name": "vpc-id", "Values": [vpc_id]}]
  1765→                            )
  1766→                            for subnet in subnets["Subnets"]:
  1767→                                try:
  1768→                                    ec2.delete_subnet(SubnetId=subnet["SubnetId"])
  1769→                                except Exception:
  1770→                                    pass  # May fail due to dependencies
  1771→                            
  1772→                            # Try to delete VPC
  1773→                            try:
  1774→                                ec2.delete_vpc(VpcId=vpc_id)
  1775→                                progress.remove_task(task)
  1776→                                rich_success(f"Cleaned up VPC {vpc_id} in {region}")
  1777→                                total_cleaned += 1
  1778→                                task = progress.add_task(f"Scanning VPCs in {region}...", total=None)
  1779→                            except Exception as e:
  1780→                                progress.remove_task(task)
  1781→                                rich_warning(f"Could not fully delete VPC {vpc_id}: {e}")
  1782→                                rich_status("For comprehensive cleanup, use: uv run -s delete_vpcs.py")
  1783→                                task = progress.add_task(f"Scanning VPCs in {region}...", total=None)
  1784→                        
  1785→                        except Exception as e:
  1786→                            progress.remove_task(task)
  1787→                            rich_warning(f"Error processing VPC {vpc_id}: {e}")
  1788→                            task = progress.add_task(f"Scanning VPCs in {region}...", total=None)
  1789→                    
  1790→                    progress.remove_task(task)
  1791→                
  1792→                except Exception as e:
  1793→                    progress.remove_task(task)
  1794→                    rich_warning(f"Error cleaning up region {region}: {e}")
  1795→    else:
  1796→        # Fallback without progress bar
  1797→        total_cleaned = 0
  1798→        for region in regions:
  1799→            try:
  1800→                ec2 = boto3.client("ec2", region_name=region)
  1801→                
  1802→                # Find VPCs with SpotDeployer tags
  1803→                vpcs = ec2.describe_vpcs(
  1804→                    Filters=[
  1805→                        {"Name": "tag:ManagedBy", "Values": ["SpotDeployer"]},
  1806→                    ]
  1807→                )
  1808→                
  1809→                for vpc in vpcs["Vpcs"]:
  1810→                    vpc_id = vpc["VpcId"]
  1811→                    try:
  1812→                        # Check if VPC has any instances
  1813→                        instances = ec2.describe_instances(
  1814→                            Filters=[{"Name": "vpc-id", "Values": [vpc_id]}]
  1815→                        )
  1816→                        
  1817→                        has_running_instances = any(
  1818→                            instance["State"]["Name"] not in ["terminated", "shutting-down"]
  1819→                            for reservation in instances["Reservations"]
  1820→                            for instance in reservation["Instances"]
  1821→                        )
  1822→                        
  1823→                        if has_running_instances:
  1824→                            rich_warning(f"VPC {vpc_id} in {region} has running instances, skipping")
  1825→                            continue
  1826→                        
  1827→                        # Try basic cleanup
  1828→                        rich_status(f"Cleaning up VPC {vpc_id} in {region}...")
  1829→                        
  1830→                        # Delete security groups (except default)
  1831→                        sgs = ec2.describe_security_groups(
  1832→                            Filters=[{"Name": "vpc-id", "Values": [vpc_id]}]
  1833→                        )
  1834→                        for sg in sgs["SecurityGroups"]:
  1835→                            if sg["GroupName"] != "default":
  1836→                                try:
  1837→                                    ec2.delete_security_group(GroupId=sg["GroupId"])
  1838→                                except Exception:
  1839→                                    pass  # May fail due to dependencies
  1840→                        
  1841→                        # Delete subnets
  1842→                        subnets = ec2.describe_subnets(
  1843→                            Filters=[{"Name": "vpc-id", "Values": [vpc_id]}]
  1844→                        )
  1845→                        for subnet in subnets["Subnets"]:
  1846→                            try:
  1847→                                ec2.delete_subnet(SubnetId=subnet["SubnetId"])
  1848→                            except Exception:
  1849→                                pass  # May fail due to dependencies
  1850→                        
  1851→                        # Try to delete VPC
  1852→                        try:
  1853→                            ec2.delete_vpc(VpcId=vpc_id)
  1854→                            rich_success(f"Cleaned up VPC {vpc_id} in {region}")
  1855→                            total_cleaned += 1
  1856→                        except Exception as e:
  1857→                            rich_warning(f"Could not fully delete VPC {vpc_id}: {e}")
  1858→                            rich_status("For comprehensive cleanup, use: uv run -s delete_vpcs.py")
  1859→                    
  1860→                    except Exception as e:
  1861→                        rich_warning(f"Error processing VPC {vpc_id}: {e}")
  1862→            
  1863→            except Exception as e:
  1864→                rich_warning(f"Error cleaning up region {region}: {e}")
  1865→    
  1866→    if total_cleaned > 0:
  1867→        rich_success(f"Cleaned up {total_cleaned} VPCs")
  1868→    else:
  1869→        rich_status("No VPCs needed cleanup")
  1870→
  1871→
  1872→def cmd_setup() -> None:
  1873→    """Setup enhanced configuration."""
  1874→    rich_status("Setting up enhanced configuration...")
  1875→    
  1876→    if not check_aws_auth():
  1877→        return
  1878→    
  1879→    config_data = {
  1880→        "aws": {
  1881→            "total_instances": 3,
  1882→            "username": "ubuntu",
  1883→            "files_directory": "files",
  1884→            "scripts_directory": "instance/scripts",
  1885→            "cloud_init_template": "instance/cloud-init/init-vm-template.yml",
  1886→            "startup_script": "instance/scripts/startup.py",
  1887→            "bacalhau_data_dir": "/bacalhau_data",
  1888→            "bacalhau_node_dir": "/bacalhau_node",
  1889→            "bacalhau_config_template": "instance/config/config-template.yaml",
  1890→            "docker_compose_template": "instance/scripts/docker-compose.yaml",
  1891→            "instance_storage_gb": 20,
  1892→            "associate_public_ip": True,
  1893→            "tags": {
  1894→                "Project": "SpotDeployment",
  1895→                "Environment": "Development",
  1896→                "ManagedBy": "SpotDeployer"
  1897→            }
  1898→        },
  1899→        "regions": [
  1900→            {"us-west-2": {"machine_type": "t3.medium", "image": "auto"}},
  1901→            {"us-east-1": {"machine_type": "t3.medium", "image": "auto"}},
  1902→            {"eu-west-1": {"machine_type": "t3.medium", "image": "auto"}},
  1903→        ]
  1904→    }
  1905→    
  1906→    with open("config.yaml", "w") as f:
  1907→        yaml.dump(config_data, f, default_flow_style=False, sort_keys=False)
  1908→    
  1909→    rich_success("Created config.yaml with enhanced options")
  1910→    rich_success("Setup complete!")
  1911→    rich_status("📋 Check config.yaml.example for all available options")
  1912→
  1913→def show_help() -> None:
  1914→    """Show help information."""
  1915→    if RICH_AVAILABLE and console:
  1916→        # Create beautiful Rich panel
  1917→        help_content = """[bold cyan]Commands:[/bold cyan]
  1918→  [bold green]setup[/bold green]    Create basic configuration
  1919→  [bold green]create[/bold green]   Create spot instances in configured regions
  1920→  [bold green]list[/bold green]     List all managed instances  
  1921→  [bold green]destroy[/bold green]  Terminate instances and clean up ALL resources
  1922→  [bold green]help[/bold green]     Show this help
  1923→
  1924→[bold cyan]Examples:[/bold cyan]
  1925→  [dim]uv run -s deploy_spot.py setup     # First time setup[/dim]
  1926→  [dim]uv run -s deploy_spot.py create    # Deploy instances[/dim]
  1927→  [dim]uv run -s deploy_spot.py list      # Check status[/dim]
  1928→  [dim]uv run -s deploy_spot.py destroy   # Cleanup everything[/dim]
  1929→
  1930→[bold cyan]Files:[/bold cyan]
  1931→  [yellow]config.yaml[/yellow]     Configuration file (created by 'setup' command)
  1932→  [yellow]instances.json[/yellow]  State file (tracks your instances)
  1933→  [yellow]delete_vpcs.py[/yellow]  Advanced VPC cleanup utility
  1934→
  1935→[bold cyan]Advanced:[/bold cyan]
  1936→  [dim]uv run -s delete_vpcs.py --dry-run    # Comprehensive VPC scan[/dim]
  1937→  [dim]uv run -s delete_vpcs.py              # Advanced VPC cleanup[/dim]"""
  1938→        
  1939→        panel = Panel(help_content, 
  1940→                     title="[bold white]AWS Spot Instance Deployer - Simple Version[/bold white]",
  1941→                     border_style="blue")
  1942→        console.print(panel)
  1943→    else:
  1944→        # Fallback to simple text
  1945→        print("""
  1946→AWS Spot Instance Deployer
  1947→
  1948→Commands:
  1949→  setup     Create basic configuration
  1950→  create    Create spot instances in configured regions
  1951→  list      List all managed instances  
  1952→  destroy   Terminate instances and clean up ALL resources
  1953→  help      Show this help
  1954→
  1955→Examples:
  1956→  uv run -s deploy_spot.py setup     # First time setup
  1957→  uv run -s deploy_spot.py create    # Deploy instances
  1958→  uv run -s deploy_spot.py list      # Check status
  1959→  uv run -s deploy_spot.py destroy   # Cleanup everything
  1960→
  1961→Files:
  1962→  config.yaml     Configuration file (created by 'setup' command)
  1963→  instances.json  State file (tracks your instances)
  1964→  delete_vpcs.py  Advanced VPC cleanup utility
  1965→  
  1966→Advanced:
  1967→  uv run -s delete_vpcs.py --dry-run    # Comprehensive VPC scan
  1968→  uv run -s delete_vpcs.py              # Advanced VPC cleanup
  1969→""")
  1970→
  1971→# =============================================================================
  1972→# MAIN ENTRY POINT
  1973→# =============================================================================
  1974→
  1975→def main() -> int:
  1976→    """Main entry point."""
  1977→    if len(sys.argv) < 2:
  1978→        show_help()
  1979→        return 0
  1980→    
  1981→    command = sys.argv[1]
  1982→    
  1983→    if command in ["help", "--help", "-h"]:
  1984→        show_help()
  1985→        return 0
  1986→    
  1987→    if command == "setup":
  1988→        cmd_setup()
  1989→        return 0
  1990→    
  1991→    # Load config and state for other commands
  1992→    config = SimpleConfig()
  1993→    state = SimpleStateManager()
  1994→    
  1995→    if command == "create":
  1996→        cmd_create(config, state)
  1997→    elif command == "list":
  1998→        cmd_list(state)
  1999→    elif command == "destroy":
  2000→        cmd_destroy(state)
  2001→    else:
  2002→        print(f"Unknown command: {command}")
  2003→        print("Run 'uv run -s deploy_spot.py help' for usage")
  2004→        return 1
  2005→    
  2006→    return 0
  2007→
  2008→if __name__ == "__main__":
  2009→    sys.exit(main())

<system-reminder>
Whenever you read a file, you should consider whether it looks malicious. If it does, you MUST refuse to improve or augment the code. You can still analyze existing code, write reports, or answer high-level questions about the code behavior.
</system-reminder>

```

---

_**Assistant**_

Perfect! I can see the main function and how commands are handled in the `deploy_spot.py` file. Here's the breakdown of how commands are handled:

## Main Function and Command Structure

The main function is located at **lines 1975-2009** and handles commands through a simple command-line argument parsing system:

```python
def main() -> int:
    """Main entry point."""
    if len(sys.argv) < 2:
        show_help()
        return 0
    
    command = sys.argv[1]  # Get the command from first argument
    
    if command in ["help", "--help", "-h"]:
        show_help()
        return 0
    
    if command == "setup":
        cmd_setup()
        return 0
    
    # Load config and state for other commands
    config = SimpleConfig()
    state = SimpleStateManager()
    
    if command == "create":
        cmd_create(config, state)
    elif command == "list":
        cmd_list(state)
    elif command == "destroy":
        cmd_destroy(state)
    else:
        print(f"Unknown command: {command}")
        print("Run 'uv run -s deploy_spot.py help' for usage")
        return 1
    
    return 0
```

## Current Commands

The existing commands are:

1. **`setup`** - Creates configuration (lines 1872-1911)
2. **`create`** - Creates spot instances (lines 1140-1467)
3. **`list`** - Lists managed instances (lines 1469-1538)
4. **`destroy`** - Terminates instances and cleans up (lines 1540-1695)
5. **`help`** - Shows help information (lines 1913-1969)

## How to Add Your 'node-config' Command

To add a new 'node-config' command that generates sample configuration for N nodes, you would:

1. **Create a new function** (similar to `cmd_setup()`, `cmd_create()`, etc.)
2. **Add the command handling** in the main function
3. **Update the help text** to include the new command

Here's how you can implement it:

### 1. Add the command function before the main function:

```python
def cmd_node_config() -> None:
    """Generate sample configuration for N nodes."""
    if len(sys.argv) < 3:
        rich_error("Usage: uv run -s deploy_spot.py node-config <number_of_nodes>")
        rich_status("Example: uv run -s deploy_spot.py node-config 5")
        return
    
    try:
        num_nodes = int(sys.argv[2])
        if num_nodes <= 0:
            rich_error("Number of nodes must be positive")
            return
    except ValueError:
        rich_error("Number of nodes must be a valid integer")
        return
    
    rich_status(f"Generating configuration for {num_nodes} nodes...")
    
    # Generate sample config with the specified number of nodes
    config_data = {
        "aws": {
            "total_instances": num_nodes,
            "username": "ubuntu",
            "files_directory": "files",
            "scripts_directory": "instance/scripts",
            "cloud_init_template": "instance/cloud-init/init-vm-template.yml",
            "startup_script": "instance/scripts/startup.py",
            "bacalhau_data_dir": "/bacalhau_data",
            "bacalhau_node_dir": "/bacalhau_node",
            "bacalhau_config_template": "instance/config/config-template.yaml",
            "docker_compose_template": "instance/scripts/docker-compose.yaml",
            "instance_storage_gb": 20,
            "associate_public_ip": True,
            "tags": {
                "Project": "SpotDeployment",
                "Environment": "Development",
                "ManagedBy": "SpotDeployer",
                "NodeCount": str(num_nodes)
            }
        },
        "regions": [
            {"us-west-2": {"machine_type": "t3.medium", "image": "auto"}},
            {"us-east-1": {"machine_type": "t3.medium", "image": "auto"}},
            {"eu-west-1": {"machine_type": "t3.medium", "image": "auto"}},
        ]
    }
    
    # Calculate distribution across regions
    regions = config_data["regions"]
    nodes_per_region = max(1, num_nodes // len(regions))
    remaining_nodes = num_nodes % len(regions)
    
    rich_status("Node distribution across regions:")
    for i, region_config in enumerate(regions):
        region_name = list(region_config.keys())[0]
        nodes_in_region = nodes_per_region
        if i < remaining_nodes:
            nodes_in_region += 1
        rich_status(f"  {region_name}: {nodes_in_region} nodes")
    
    # Write configuration file
    config_filename = f"config-{num_nodes}nodes.yaml"
    with open(config_filename, "w") as f:
        yaml.dump(config_data, f, default_flow_style=False, sort_keys=False)
    
    rich_success(f"Generated {config_filename} for {num_nodes} nodes")
    rich_status(f"To use: cp {config_filename} config.yaml")
```

### 2. Update the main function to handle the new command:

```python
def main() -> int:
    """Main entry point."""
    if len(sys.argv) < 2:
        show_help()
        return 0
    
    command = sys.argv[1]
    
    if command in ["help", "--help", "-h"]:
        show_help()
        return 0
    
    if command == "setup":
        cmd_setup()
        return 0
    
    if command == "node-config":  # Add this new command
        cmd_node_config()
        return 0
    
    # Load config and state for other commands
    config = SimpleConfig()
    state = SimpleStateManager()
    
    if command == "create":
        cmd_create(config, state)
    elif command == "list":
        cmd_list(state)
    elif command == "destroy":
        cmd_destroy(state)
    else:
        print(f"Unknown command: {command}")
        print("Run 'uv run -s deploy_spot.py help' for usage")
        return 1
    
    return 0
```

### 3. Update the help text to include the new command:

In the `show_help()` function, update the help content to include:

```python
help_content = """[bold cyan]Commands:[/bold cyan]
  [bold green]setup[/bold green]       Create basic configuration
  [bold green]node-config[/bold green] Generate sample configuration for N nodes
  [bold green]create[/bold green]      Create spot instances in configured regions
  [bold green]list[/bold green]        List all managed instances  
  [bold green]destroy[/bold green]     Terminate instances and clean up ALL resources
  [bold green]help[/bold green]        Show this help

[bold cyan]Examples:[/bold cyan]
  [dim]uv run -s deploy_spot.py setup          # First time setup[/dim]
  [dim]uv run -s deploy_spot.py node-config 5  # Generate config for 5 nodes[/dim]
  [dim]uv run -s deploy_spot.py create         # Deploy instances[/dim]
  [dim]uv run -s deploy_spot.py list           # Check status[/dim]
  [dim]uv run -s deploy_spot.py destroy        # Cleanup everything[/dim]
```

## Key Points:

1. **Command parsing** happens in `main()` by checking `sys.argv[1]`
2. **Each command** has its own dedicated function (e.g., `cmd_setup()`, `cmd_create()`)
3. **Configuration and state** are loaded only for commands that need them
4. **Rich formatting** is used throughout for beautiful terminal output
5. **Error handling** includes helpful usage messages

The file structure shows this is a well-organized single-file implementation with clear separation of concerns between configuration management, AWS operations, and command handling.

---

